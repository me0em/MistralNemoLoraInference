# MistralNemoLoraInference


### What is it?
Inference LLM with LoRA as OpenAI-compatible API

### Using
1. Install python3.10 and create virtual env with it
2. Install poetry: `python -m pip install poetry`
3. Install all dependencies: `poetry install`
4. Run the backend: `python main.py` or `poetry run python main.py`
